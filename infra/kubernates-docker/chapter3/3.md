---
description: 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커
---

# 3.3 쿠버네티스 연결을 담당하는 서비스

쿠버네티스에서는 외부에서 쿠버네티스 클러스터에 접속하는 방법을 **서비스**라고 한다.

## 1. 가장 간단하게 연결하는 노드포트

외부에서 쿠버네티스 클러스터의 내부에 접속하는 가장 쉬운 방법은 **노드포트** 서비스를 이용하는 것이다.

모든 워커 노드의 특정 포트(노드포트)를 열고 여기로 오는 모든 요청을 노드포트 서비스로 전달한다. 그리고 노드포트 서비스는 해당 업무를 처리할 수 있는 파드로 요청을 전달한다.

### 노드포트 서비스로 외부에서 접속하기

오브젝트 스펙

```yml
apiVersion: v1
kind: Service
metadata:
    name: np-svc
spec:
    # 셀렉터의 레이블 지정 
    selector:
        app: np-pods
    # 사용할 프로토콜과 포트들을 지정
    ports:
        - name: http
          protocol: TCP
          port: 80
          targetPort: 80
          nodePort: 30000
    # 서비스 타입을 설정
    type: NodePort
```

CLUSTER-IP : 클러스터 내부에서 사용하는 IP로 자동으로 지정된다.

### 부하 분산 테스트하기

노드포트의 오브젝트 스펙과 디플로이먼트의 이름을 확인해 동일하면 같은 파드라고 간주한다.

### expose로 노드포트 서비스 생성하기

```shell
kubectl expose deployment ${디플로이먼트 이름} --type=NodePort --name=${서비스 이름} --port=${서비스가 파드로 보내줄 연결 포트}
```

`expose`를 사용하면 노드포트의 포트 번호를 지정할 수 없다.

## 2. 사용 목적별로 연결하는 인그레스

노드포트 서비스는 포트를 중복 사용할 수 없어서 1개의 노드포트에 1개의 디플로어먼트만 적용된다.

여러 개의 디플로이먼트가 있을 때에는 인그레스를 사용한다.

인그레스는 고유한 주소를 제공해 사용 목적에 따라 다른 응답을 제공할 수 있고, 트래픽에 대한 L4/L7 로드밸런서와 보안 인증서를 처리하는 기능을 제공한다.

인그레스를 사용하려면 인그레스 컨트롤러가 필요하다.

인그레스 컨트롤러의 궁긍적인 목적은 사용자가 접속하는 경로에 따라 다른 결과값을 제공한다는 것이다.

인그레스를 위한 설정 파일은 들어오는 주소 값과 포트에 따라 노출된 서비스를 연결하는 역할을 설정한다.

### 예제

NGINX 인그레스 컨트롤러 단계

1. 사용자는 노드마다 설정된 노드포트를 통해 노드포트 서비스로 접속한다. 이때 노드포트 서비스를 NGINX 인그레스 컨트롤러로 구성한다.
2. NGINX 인그레스 컨트롤러는 사용자의 접속 경로에 따라 적합한 클러스터 IP 서비스로 경로를 제공한다.
3. 클러스터 IP 서비스는 사용자를 해당 파드로 연결해 준다.

```yaml
# 인그레스 설정
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
    # Ingress 이름
    # 이름을 통해서 통신할 ingress 컨트롤러 확인
    name: ingress-nginx
    # 메타데이터의 기록 및 변경
    annotations:
        # rewrite-target을 / (기본주소)로 지정한다.
        nginx.ingress.kubernetes.io/rewrite-target: /
spec:
    # 규칙 지정
    rules:
    - http:
        paths:
        # 기본 경로 규칙
        - path:
          # 연결되는 서비스와 포트
          backend:
            serviceName: hname-svc-default
            servicePort: 80
        # 기본 경로에 ip 라는 이름의 경로 추가
        - path: /ip
          # 연결되는 서비스와 포트
          backend:
            serviceName: ip-svc
            servicePort: 80
        # 기본 경로에 your-directory 라는 이름의 경로 추가
        - path: /your-directory
          # 연결되는 서비스와 포트
          backend:
            serviceName: your-svc
            servicePort: 80
```

- 외부에서 주소 값과 노드포트를 가지고 들어오는 것은 `hname-svc-default` 서비스와 연결된 파드로 넘긴다.
- 외부에서 들어오는 주소 값, 노드포트와 함께 뒤에 `/ip`를 추가한 주소 값은 `ip-svc` 서비스와 연결된 파드로 접속한다.

```shell
# 인그레스 설정 파일이 제대로 등록됐는지 확인하기
kubectl get ingress

# 인그레스에 적용된 내용을 YAML 형식으로 출력하기 (시스템에서 자동으로 생성하는 것까지 확인 가능)
kubectl get ingress -o yaml
```

외부에서 NGINX 인그레스 컨트롤러에 접속할 수 있게 노드포트 서비스로 NGINX 인그레스 컨트롤러를 외부에 노출한다.

```yaml
# NGINX 인그레스 컨트롤러 설정
apiVersion: v1
kind: Service
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx
spec:
  # 사용할 프로토콜과 포트들을 지정
  ports:
    # http에 대한 프로토콜 및 포트 지정
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30100
    # https에 대한 프로토콜 및 포트 지정
    - name: https
      protocol: TCP
      port: 443
      targetPort: 443
      nodePort: 30101
    # 셀렉터의 레이블 지정
    selector:
      app.kubernetes.io/name: ingress-nginx
    # 서비스 타입 설정 
    type: NodePort
```

- http를 처리하기 위해 30100번 포트로 들어온 요청을 80번 포트로 넘긴다.
- https를 처리하기 위해 30101번 포트로 들어온 것을 443번 포트로 넘긴다.

```shell
# expose 명령으로 디플로이먼트 서비스로 노출하기
kubectl expose deployment ${디플로이먼트 이름} --name=${노출되는 이름} --port${연결 포트번호}
```

## 3. 클라우드에서 쉽게 구성 가능한 로드밸런서

앞에서 배운 연결 방식은 들어오는 요청을 모두 워커 노드의 노드포트를 통해 노드포트 서비스로 이동하고 이를 다시 쿠버네티스의 파드로 보내는 구조이고, 비효율적이다.

쿠버네티스에서는 **로드밸런서**라는 서비스 타입을 제공해 간단한 구조로 파드를 외부에 노출하고 부하를 분산한다.

로드밸런서를 사용하려면 로드밸런서를 이미 구현해 둔 서비스 업체(EKS, GKE, AKS)의 도움을 받아 쿠버네티스 클러스터 외부에 구현해야 한다.

```shell
kubectl expose deployment ${디플로이먼트 이름} --type=LoadBalancer --name=${노출되는 이름}
```

- 쿠버네티스 클러스에 로드밸런서 서비스가 생성돼 외부와 통신할 수 있는 IP가 부여되고, 외부와 통신할 수 있으며 부하가 분산된다.

## 4. 온프레미스에서 로드밸런서를 제공하는 MetalLB

온프레미스에서 로드밸런서를 사용하려면 내부에 로드밸런서 서비스를 받아주는 구성이 필요한데, 이를 지원하는 것이 **MetalLB** 이다.

MetalLB는 베어메탈(운영체제가 설치되지 않은 하드웨어)로 구성된 쿠버네티스에서도 로드밸런서를 사용할 수 있게 고안된 프로젝트이다.

MetalLB는 특별한 네트워크 설정이나 구성이 있는 것이 아니라 기존의 L2 네트워크(ARP/NDP)와 L3 네트워크(BGP)로 로드밸런서를 구현한다. 그러므로 네트워크를 새로 배워야 할 부담이 없으며, 연동하기도 매우 쉽다.

MetalLB 컨트롤러는 작동 방식(프로토콜)을 정의하고, EXTERNAL-IP를 부여해 관리한다.

MetalLB 스피커는 정해진 작동방식(L2/ARP, L3/BGP)에 따라 경로를 만들 수 있도록 네트워크 정보를 광고하고 수집해 각 파드의 경로를 제공한다. 이때, L2는 스피커 중에서 리더를 선출해 경로 제공을 총괄하게 한다.

MetalLB 설정을 적용하기 위해 ConfigMap을 사용한다. ConfigMap은 설정이 정의된 포맷이라고 생각하면 된다.

```yaml
# ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  namesapce: metallb-system
  name: config
data:
  config: |
    # 세부 설정
    address-pools: 
    - name: nginx-ip-range
      # metallb에서 제공하는 로드밸런서의 동작 방식
      protocol: layer2
      # metallb에서 제공하는 로드밸런서의 Ext 주소
      addresses:
      - 192.168.1.11-192.168.1.13 
```

```shell
# ConfigMap 확인하기
kubectl get configmap -n ${네임스페이스}

# 디플로이먼트를 로드밸런서 서비스로 노출하기
kubectl expose deployment ${디플로이먼트 이름} --type=LoadBalancer --name=${노출되는 이름} --port=${연결 포트 번호}
```

## 5. 부하에 따라 자동으로 파드 수를 조절하는 HPA

쿠버네티스는 부하량에 따라 디플로이먼트의 파드 수를 유동적으로 관리하는 기능을 제공한다. 이를 **HPA(Horizontal Pod Autoscaler)** 라고 한다.

```shell
# 부하 확인하기
kubectl top pods
```

HPA가 자원을 요청할 때 메트릭 서버(모니터링 도구)를 통해 계측값을 전달받는다. (힙스터 : 쿠버네티스 1.13 이전 버전에서의 모니터링 도구)

원본 소스 : <https://github.com/kubernetes-sigs/metrics-server>

```yaml
spec:
  containers:
  - image: sysnet4admin/echo-hname
    imagePullPolicy: Always
    name: echo-hname
    resources:
      # 파드 증설 기준
      requests:
        # 파드의 CPU 0.01 사용을 기준으로 파드를 증설한다.
        cpu: "10m" # 1000m = 1개의 CPU
      # CPU 사용제한
      limits: 
        cpu: "50m"
    ...
```

```shell
kubectl autoscale deployment ${디플로이먼트 이름} --min=${최소 파드의 수} --max=${최대 파드의 수} --cpu-percent=${autoscale 기준 CPU 사용량}
```

{% hint style="info" %}
디플로이먼트 부하 총량을 가지고 HPA가 작동한다.

만약 1개의 파드에 부하가 발생하더라도 해당 부하는 분산되지 않는다.

부하 분산을 위해서는 쿠버네티스 서비스를 통해 파드 그룹인 디플로이먼트에 도달해야 한다.
{% endhint %}

```shell
# HPA의 현재 상태 요약 보기
kubectl get hps
```